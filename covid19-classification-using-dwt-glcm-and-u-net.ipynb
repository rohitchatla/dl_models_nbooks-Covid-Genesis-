{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport glob\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport cv2\n\nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import Dense, Input, Dropout, concatenate\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n\nfrom skimage.feature import greycomatrix, greycoprops\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-26T09:09:54.525086Z","iopub.execute_input":"2021-12-26T09:09:54.525350Z","iopub.status.idle":"2021-12-26T09:10:00.963382Z","shell.execute_reply.started":"2021-12-26T09:09:54.525321Z","shell.execute_reply":"2021-12-26T09:10:00.962654Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_dir = '../input/chest-xray-covid19-pneumonia/Data/train/*'\ntest_dir = '../input/chest-xray-covid19-pneumonia/Data/test/*'\ntrain2_covid_dir = '../input/covid19-radiography-database/COVID-19_Radiography_Dataset/COVID'","metadata":{"execution":{"iopub.status.busy":"2021-12-26T09:10:04.074967Z","iopub.execute_input":"2021-12-26T09:10:04.075903Z","iopub.status.idle":"2021-12-26T09:10:04.081001Z","shell.execute_reply.started":"2021-12-26T09:10:04.075853Z","shell.execute_reply":"2021-12-26T09:10:04.079436Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"SIZE = 128\nBATCH_SIZE = 64\nTARGET_SIZE = (SIZE,SIZE)\nEPOCH_NUM = 200","metadata":{"execution":{"iopub.status.busy":"2021-12-26T09:10:24.917323Z","iopub.execute_input":"2021-12-26T09:10:24.917799Z","iopub.status.idle":"2021-12-26T09:10:24.922632Z","shell.execute_reply.started":"2021-12-26T09:10:24.917755Z","shell.execute_reply":"2021-12-26T09:10:24.921569Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"categories_dict = {\n  0: \"PNEUMONIA\",\n  1: \"NORMAL\",\n  2: \"COVID19\"\n}","metadata":{"execution":{"iopub.status.busy":"2021-12-26T09:10:31.305490Z","iopub.execute_input":"2021-12-26T09:10:31.305859Z","iopub.status.idle":"2021-12-26T09:10:31.310177Z","shell.execute_reply.started":"2021-12-26T09:10:31.305819Z","shell.execute_reply":"2021-12-26T09:10:31.309540Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"img=cv2.imread('../input/covid19-radiography-database/COVID-19_Radiography_Dataset/COVID/COVID-1013.png')\nplt.imshow(img)\nimg.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-26T09:12:42.264522Z","iopub.execute_input":"2021-12-26T09:12:42.265355Z","iopub.status.idle":"2021-12-26T09:12:42.529634Z","shell.execute_reply.started":"2021-12-26T09:12:42.265310Z","shell.execute_reply":"2021-12-26T09:12:42.528969Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Extracting subbands using DWT + Merging subbands in one image with shape(128,128,4)","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nimport pywt\nimport pywt.data\n\n\n# Load image\noriginal = cv2.resize(img,(256,256)) \noriginal = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)\n# Wavelet transform of image, and plot approximation and details\ntitles = ['Approximation', ' Horizontal detail',\n      'Vertical detail', 'Diagonal detail']\ncoeffs2 = pywt.dwt2(original, 'bior1.3')\nLL, (LH, HL, HH) = coeffs2\nfig = plt.figure(figsize=(12, 3))\nfor i, a in enumerate([LL, LH, HL, HH]):\n  ax = fig.add_subplot(1, 4, i + 1)\n  ax.imshow(a, interpolation=\"nearest\", cmap=plt.cm.gray)\n  ax.set_title(titles[i], fontsize=10)\n  ax.set_xticks([])\n  ax.set_yticks([])\n\nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-26T09:12:43.945975Z","iopub.execute_input":"2021-12-26T09:12:43.946706Z","iopub.status.idle":"2021-12-26T09:12:44.254543Z","shell.execute_reply.started":"2021-12-26T09:12:43.946657Z","shell.execute_reply":"2021-12-26T09:12:44.253830Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"## Merging \nmerged = cv2.merge([LL, LH, HL, HH])\nprint(merged.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-26T09:12:44.482817Z","iopub.execute_input":"2021-12-26T09:12:44.483048Z","iopub.status.idle":"2021-12-26T09:12:44.492758Z","shell.execute_reply.started":"2021-12-26T09:12:44.483022Z","shell.execute_reply":"2021-12-26T09:12:44.491861Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Loading Train and Test Data","metadata":{}},{"cell_type":"code","source":"train_images = []\ntrain_labels = [] \nlabel = 0\n\n#Importing the first training dataset\n\nfor directory_path in glob.glob(train_dir):\n    assert categories_dict[label] == os.path.normpath(directory_path).split(os.path.sep)[-1]\n    print(categories_dict[label])\n    counter = 1\n    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n        if(counter%200==0): print(counter,\"images loaded\")\n        img = cv2.imread(img_path, 0)\n        img = cv2.resize(img, TARGET_SIZE)\n        coeffs2 = pywt.dwt2(img, 'bior1.3')\n        LL, (LH, HL, HH) = coeffs2\n        for i in [LL,LH,HL,HH]:\n            i=cv2.resize(i,TARGET_SIZE)\n        img = cv2.merge([LL, LH, HL, HH])\n        img=cv2.resize(img,TARGET_SIZE)\n        train_images.append(img)\n        train_labels.append(label)\n        counter+=1\n        if(counter%1500==0): break\n    \n    print(counter,\"images loaded\")\n    label +=1\n    \n#Importing the additional training dataset\n\nprint(\"additional\",categories_dict[2],\"data\")    \naddit_counter = 1\nfor img_path in glob.glob(os.path.join(train2_covid_dir, \"*.png\")):\n    if(addit_counter%200==0): print(addit_counter,\"images loaded\")\n    img = cv2.imread(img_path, 0)\n    img = cv2.resize(img, TARGET_SIZE)\n    coeffs2 = pywt.dwt2(img, 'bior1.3')\n    LL, (LH, HL, HH) = coeffs2\n    for i in [LL,LH,HL,HH]:\n            i=cv2.resize(i,TARGET_SIZE)\n    img = cv2.merge([LL, LH, HL, HH])\n    img=cv2.resize(img,TARGET_SIZE)\n    train_images.append(img)\n    train_labels.append(2)\n    addit_counter+=1\n    if(addit_counter%1000==0): break\nprint(addit_counter,\"images loaded\")\n\nx_train = np.array(train_images)\ny_train = to_categorical(train_labels, 3)","metadata":{"execution":{"iopub.status.busy":"2021-12-26T09:12:51.378553Z","iopub.execute_input":"2021-12-26T09:12:51.378823Z","iopub.status.idle":"2021-12-26T09:14:32.427055Z","shell.execute_reply.started":"2021-12-26T09:12:51.378793Z","shell.execute_reply":"2021-12-26T09:14:32.426286Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"x_train[200].shape","metadata":{"execution":{"iopub.status.busy":"2021-12-26T09:14:32.428658Z","iopub.execute_input":"2021-12-26T09:14:32.428905Z","iopub.status.idle":"2021-12-26T09:14:32.434741Z","shell.execute_reply.started":"2021-12-26T09:14:32.428869Z","shell.execute_reply":"2021-12-26T09:14:32.433970Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"test_images = []\ntest_labels = []\nlabel = 0\n\n#importing the testing dataset\n\nfor directory_path in glob.glob(test_dir):\n    assert categories_dict[label] == os.path.normpath(directory_path).split(os.path.sep)[-1]\n    print(categories_dict[label])\n    counter = 1\n    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n        if(counter%100==0): print(counter, \"images loaded\")\n        img = cv2.imread(img_path, 0)\n        img = cv2.resize(img, TARGET_SIZE)\n        coeffs2 = pywt.dwt2(img, 'bior1.3')\n        LL, (LH, HL, HH) = coeffs2\n        for i in [LL,LH,HL,HH]:\n            i=cv2.resize(i,TARGET_SIZE)\n        img = cv2.merge([LL, LH, HL, HH])\n        img=cv2.resize(img,TARGET_SIZE)\n        test_images.append(img)\n        test_labels.append(label)\n        counter+=1\n    \n    print(counter,\"images loaded\")\n    label +=1\n\ntest_images = np.array(test_images)\ntest_labels = to_categorical(test_labels, 3)","metadata":{"execution":{"iopub.status.busy":"2021-12-26T09:14:32.436104Z","iopub.execute_input":"2021-12-26T09:14:32.436524Z","iopub.status.idle":"2021-12-26T09:15:05.052597Z","shell.execute_reply.started":"2021-12-26T09:14:32.436487Z","shell.execute_reply":"2021-12-26T09:15:05.051126Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"test_images[0].shape","metadata":{"execution":{"iopub.status.busy":"2021-12-26T09:17:11.184490Z","iopub.execute_input":"2021-12-26T09:17:11.184863Z","iopub.status.idle":"2021-12-26T09:17:11.190409Z","shell.execute_reply.started":"2021-12-26T09:17:11.184816Z","shell.execute_reply":"2021-12-26T09:17:11.189472Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### Splitting data into train and validation dataset","metadata":{}},{"cell_type":"code","source":"train_test_split(train_images, train_labels)\ntrain_images, val_images, train_labels, val_labels = train_test_split(x_train, \n                                                                      y_train, \n                                                                      test_size=0.15, \n                                                                      random_state=69)","metadata":{"execution":{"iopub.status.busy":"2021-12-26T09:17:18.108648Z","iopub.execute_input":"2021-12-26T09:17:18.109097Z","iopub.status.idle":"2021-12-26T09:17:18.724047Z","shell.execute_reply.started":"2021-12-26T09:17:18.109063Z","shell.execute_reply":"2021-12-26T09:17:18.723337Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"print(\"train:\",train_images.shape[0],\", test:\",test_images.shape[0],\", val:\",val_images.shape[0])","metadata":{"execution":{"iopub.status.busy":"2021-12-26T09:17:21.245373Z","iopub.execute_input":"2021-12-26T09:17:21.245919Z","iopub.status.idle":"2021-12-26T09:17:21.251649Z","shell.execute_reply.started":"2021-12-26T09:17:21.245883Z","shell.execute_reply":"2021-12-26T09:17:21.250851Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Feature Extraction from subbands using GLCM","metadata":{}},{"cell_type":"code","source":"from skimage import util, exposure, data\ndef feature_glcm(image):\n    glcm_dataset = pd.DataFrame()\n    [LL,LH,HL,HH]=cv2.split(image)\n    df = pd.DataFrame()    \n    for n ,img in enumerate([LL,LH,HL,HH]):\n            img = exposure.rescale_intensity(img, out_range=(0, 1))\n            bin_width = 32\n            im = util.img_as_ubyte(img)\n            img = im//bin_width\n            GLCM = greycomatrix(img, [1], [0])       \n            GLCM_Energy = greycoprops(GLCM, 'energy')[0]\n            df['Energy__subband'+str(n)] = GLCM_Energy\n            GLCM_corr = greycoprops(GLCM, 'correlation')[0]\n            df['Corr__subband'+str(n)] = GLCM_corr       \n            GLCM_diss = greycoprops(GLCM, 'dissimilarity')[0]\n            df['Diss_sim__subband'+str(n)] = GLCM_diss       \n            GLCM_hom = greycoprops(GLCM, 'homogeneity')[0]\n            df['Homogen__subband'+str(n)] = GLCM_hom       \n            GLCM_contr = greycoprops(GLCM, 'contrast')[0]\n            df['Contrast__subband'+str(n)] = GLCM_contr\n            GLCM_ASM = greycoprops(GLCM, 'ASM')[0]\n            df['ASM__subband'+str(n)] = GLCM_ASM\n\n    glcm_dataset = glcm_dataset.append(df)\n    return glcm_dataset","metadata":{"execution":{"iopub.status.busy":"2021-12-26T09:17:27.098929Z","iopub.execute_input":"2021-12-26T09:17:27.099191Z","iopub.status.idle":"2021-12-26T09:17:27.111941Z","shell.execute_reply.started":"2021-12-26T09:17:27.099156Z","shell.execute_reply":"2021-12-26T09:17:27.111200Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"feature_glcm(merged)","metadata":{"execution":{"iopub.status.busy":"2021-12-26T09:17:31.475601Z","iopub.execute_input":"2021-12-26T09:17:31.476402Z","iopub.status.idle":"2021-12-26T09:17:31.535627Z","shell.execute_reply.started":"2021-12-26T09:17:31.476355Z","shell.execute_reply":"2021-12-26T09:17:31.534829Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def feature_extractor(images):\n    image_dataset = pd.DataFrame()\n    for image in images: \n        image_dataset = image_dataset.append(feature_glcm(image))\n        \n    return image_dataset","metadata":{"execution":{"iopub.status.busy":"2021-12-26T09:17:32.645070Z","iopub.execute_input":"2021-12-26T09:17:32.646089Z","iopub.status.idle":"2021-12-26T09:17:32.651393Z","shell.execute_reply.started":"2021-12-26T09:17:32.646037Z","shell.execute_reply":"2021-12-26T09:17:32.650492Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_df= feature_extractor(train_images)","metadata":{"execution":{"iopub.status.busy":"2021-12-26T09:17:33.585979Z","iopub.execute_input":"2021-12-26T09:17:33.586561Z","iopub.status.idle":"2021-12-26T09:19:11.020107Z","shell.execute_reply.started":"2021-12-26T09:17:33.586525Z","shell.execute_reply":"2021-12-26T09:19:11.019409Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2021-12-26T09:19:11.021851Z","iopub.execute_input":"2021-12-26T09:19:11.022095Z","iopub.status.idle":"2021-12-26T09:19:11.058165Z","shell.execute_reply.started":"2021-12-26T09:19:11.022062Z","shell.execute_reply":"2021-12-26T09:19:11.057414Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"test_df = feature_extractor(test_images)","metadata":{"execution":{"iopub.status.busy":"2021-12-26T09:19:11.059464Z","iopub.execute_input":"2021-12-26T09:19:11.059781Z","iopub.status.idle":"2021-12-26T09:19:46.067174Z","shell.execute_reply.started":"2021-12-26T09:19:11.059746Z","shell.execute_reply":"2021-12-26T09:19:46.066473Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"test_df","metadata":{"execution":{"iopub.status.busy":"2021-12-26T09:19:46.069233Z","iopub.execute_input":"2021-12-26T09:19:46.069560Z","iopub.status.idle":"2021-12-26T09:19:46.104986Z","shell.execute_reply.started":"2021-12-26T09:19:46.069523Z","shell.execute_reply":"2021-12-26T09:19:46.104234Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"val_df = feature_extractor(val_images)","metadata":{"execution":{"iopub.status.busy":"2021-12-26T09:19:46.106359Z","iopub.execute_input":"2021-12-26T09:19:46.106627Z","iopub.status.idle":"2021-12-26T09:20:03.320611Z","shell.execute_reply.started":"2021-12-26T09:19:46.106594Z","shell.execute_reply":"2021-12-26T09:20:03.319707Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"val_df","metadata":{"execution":{"iopub.status.busy":"2021-12-26T09:20:03.321827Z","iopub.execute_input":"2021-12-26T09:20:03.322236Z","iopub.status.idle":"2021-12-26T09:20:03.357743Z","shell.execute_reply.started":"2021-12-26T09:20:03.322196Z","shell.execute_reply":"2021-12-26T09:20:03.356919Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# convert from integers to floats\ntrain_images_norm = train_images.astype('float32')\ntest_images_norm = test_images.astype('float32')\nval_images_norm = val_images.astype('float32')\n# normalize to the range 0-1\ntrain_images_norm /= 255.0\ntest_images_norm /= 255.0\nval_images_norm /= 255.0","metadata":{"execution":{"iopub.status.busy":"2021-12-26T09:20:03.359163Z","iopub.execute_input":"2021-12-26T09:20:03.359508Z","iopub.status.idle":"2021-12-26T09:20:03.859198Z","shell.execute_reply.started":"2021-12-26T09:20:03.359473Z","shell.execute_reply":"2021-12-26T09:20:03.858317Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"pd.set_option(\"display.max_columns\", None)\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2021-12-26T09:20:03.903370Z","iopub.execute_input":"2021-12-26T09:20:03.903676Z","iopub.status.idle":"2021-12-26T09:20:03.943660Z","shell.execute_reply.started":"2021-12-26T09:20:03.903637Z","shell.execute_reply":"2021-12-26T09:20:03.942931Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"## Define U-NET model ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import Input, Model\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, UpSampling2D, concatenate,Flatten\nfrom tensorflow.keras.optimizers import Adam\n\n\ndef unet(pretrained_weights = None,input_size = (SIZE,SIZE,4)):\n    inputs = Input(input_size)\n    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n    drop4 = Dropout(0.5)(conv4) # for crop and copy\n    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n\n    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n    drop5 = Dropout(0.5)(conv5)\n\n    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size=(2,2))(drop5))\n    merge6 = concatenate([drop4,up6], axis = 3) # Concatenate for localization informantion\n    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n\n    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n    merge7 = concatenate([conv3,up7], axis = 3)\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n\n    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n    merge8 = concatenate([conv2,up8], axis = 3)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n\n    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n    merge9 = concatenate([conv1,up9], axis = 3)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n    conv10 = Conv2D(4, 1, activation = 'sigmoid')(conv9)\n    f=Flatten()(conv10)\n    d=Dense(4, activation=tf.keras.activations.relu)(f)\n    model = Model(inputs=inputs, outputs=d)\n    \n    model.summary()\n\n    if(pretrained_weights):\n        model.load_weights(pretrained_weights)\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-26T09:20:03.946673Z","iopub.execute_input":"2021-12-26T09:20:03.947172Z","iopub.status.idle":"2021-12-26T09:20:03.972519Z","shell.execute_reply.started":"2021-12-26T09:20:03.947131Z","shell.execute_reply":"2021-12-26T09:20:03.971581Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nimport keras\ndef build_mlp():\n    model = Sequential([\n        keras.Input(shape=24, name='Extracted_GLCM_Features'),\n        keras.layers.Dense(8, activation=tf.keras.activations.relu, name='Dense1'),\n        keras.layers.Dense(4, activation=tf.keras.activations.relu, name='Dense2')\n    ])\n    print(model.summary())\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-26T09:20:03.973827Z","iopub.execute_input":"2021-12-26T09:20:03.974242Z","iopub.status.idle":"2021-12-26T09:20:03.986274Z","shell.execute_reply.started":"2021-12-26T09:20:03.974200Z","shell.execute_reply":"2021-12-26T09:20:03.985476Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"mlp = build_mlp()\nunet = unet()\n\ncombinedInput = concatenate([mlp.output, unet.output])\n\nx = Dense(8, activation=\"relu\")(combinedInput)\nx = Dense(3, activation=\"softmax\")(x)\n\nmodel_u = Model(inputs=[mlp.input, unet.input], outputs=x)","metadata":{"execution":{"iopub.status.busy":"2021-12-26T09:20:03.989510Z","iopub.execute_input":"2021-12-26T09:20:03.990402Z","iopub.status.idle":"2021-12-26T09:20:06.170023Z","shell.execute_reply.started":"2021-12-26T09:20:03.990336Z","shell.execute_reply":"2021-12-26T09:20:06.169297Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"import tensorflow\nopt = tensorflow.keras.optimizers.Adam(learning_rate=0.005)","metadata":{"execution":{"iopub.status.busy":"2021-12-26T09:20:06.171973Z","iopub.execute_input":"2021-12-26T09:20:06.172443Z","iopub.status.idle":"2021-12-26T09:20:06.177922Z","shell.execute_reply.started":"2021-12-26T09:20:06.172390Z","shell.execute_reply":"2021-12-26T09:20:06.177026Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"model_u.compile(optimizer=opt, loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n              metrics=[keras.metrics.CategoricalAccuracy()])\n\nplot_model(model_u, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-26T09:20:06.179176Z","iopub.execute_input":"2021-12-26T09:20:06.179551Z","iopub.status.idle":"2021-12-26T09:20:07.474988Z","shell.execute_reply.started":"2021-12-26T09:20:06.179512Z","shell.execute_reply":"2021-12-26T09:20:07.474280Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ReduceLROnPlateau\n\ncb = [\n    ReduceLROnPlateau(\n        monitor='val_loss',\n        factor=0.1,\n        patience=10,\n        mode='auto',\n        min_delta=0.0002,\n        cooldown=5,\n        min_lr=10e-8,\n        verbose=1,\n    )\n]","metadata":{"execution":{"iopub.status.busy":"2021-12-26T09:20:07.477034Z","iopub.execute_input":"2021-12-26T09:20:07.477494Z","iopub.status.idle":"2021-12-26T09:20:07.483735Z","shell.execute_reply.started":"2021-12-26T09:20:07.477457Z","shell.execute_reply":"2021-12-26T09:20:07.482485Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"## Learning","metadata":{}},{"cell_type":"code","source":"train_dfu = train_df[:500]\ntrain_images_normu=train_images_norm[:500]\ntrain_labelsu=train_labels[:500]\nval_dfu=val_df[:100]\nval_images_normu=val_images_norm[:100]\nval_labelsu=val_labels[:100]\ntest_dfu = test_df[:200]\ntest_images_normu=test_images_norm[:200]\ntest_labelsu=test_labels[:200]","metadata":{"execution":{"iopub.status.busy":"2021-12-26T09:20:07.484883Z","iopub.execute_input":"2021-12-26T09:20:07.485356Z","iopub.status.idle":"2021-12-26T09:20:07.496164Z","shell.execute_reply.started":"2021-12-26T09:20:07.485322Z","shell.execute_reply":"2021-12-26T09:20:07.495403Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"dataset_inputs = tf.data.Dataset.from_tensor_slices((train_dfu, tf.expand_dims(train_images_normu, axis=-1)))\ndataset_label = tf.data.Dataset.from_tensor_slices(train_labelsu)\n\ndataset = tf.data.Dataset.zip((dataset_inputs, dataset_label)).batch(BATCH_SIZE).repeat()\nSTEP_SIZE_TRAIN= train_images_norm.shape[0]//BATCH_SIZE\n# fit model\nwith tf.device('/gpu:0'):\n    print('runnning from gpu')\n    history_u = model_u.fit(dataset, \n                        validation_data=([val_dfu, tf.expand_dims(val_images_normu, axis=-1)], val_labelsu),\n                        epochs = EPOCH_NUM, steps_per_epoch=32, callbacks=cb)","metadata":{"execution":{"iopub.status.busy":"2021-12-26T09:23:40.189265Z","iopub.execute_input":"2021-12-26T09:23:40.189536Z","iopub.status.idle":"2021-12-26T10:17:54.098959Z","shell.execute_reply.started":"2021-12-26T09:23:40.189507Z","shell.execute_reply":"2021-12-26T10:17:54.098156Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"model_u.save('unet_200itrs.h5')","metadata":{"execution":{"iopub.status.busy":"2021-12-26T10:21:16.628866Z","iopub.execute_input":"2021-12-26T10:21:16.629122Z","iopub.status.idle":"2021-12-26T10:21:17.572564Z","shell.execute_reply.started":"2021-12-26T10:21:16.629093Z","shell.execute_reply":"2021-12-26T10:21:17.571797Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"./unet_200itrs.h5\"> Download File </a>","metadata":{}},{"cell_type":"code","source":"import os \nos.chdir(r'/kaggle/working')\n\n%cd /kaggle/working\n\n\nfrom IPython.display import FileLink\nFileLink(r'unet_200itrs.h5')","metadata":{"execution":{"iopub.status.busy":"2021-12-26T10:24:39.308614Z","iopub.execute_input":"2021-12-26T10:24:39.308884Z","iopub.status.idle":"2021-12-26T10:24:39.317263Z","shell.execute_reply.started":"2021-12-26T10:24:39.308855Z","shell.execute_reply":"2021-12-26T10:24:39.316464Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"## Testing","metadata":{}},{"cell_type":"code","source":"test_inputs = tf.data.Dataset.from_tensor_slices((test_dfu, tf.expand_dims(test_images_normu, axis=-1)))\ntest_labels = tf.data.Dataset.from_tensor_slices(test_labelsu)\n\ntest_dataset = tf.data.Dataset.zip((test_inputs, test_labels)).batch(BATCH_SIZE).repeat()\nSTEP_SIZE_TEST= test_images_norm.shape[0]//BATCH_SIZE\n\nscore = model_u.evaluate(test_dataset, batch_size=BATCH_SIZE, steps=STEP_SIZE_TEST )\nprint(f'Test loss: {score[0]} / Test accuracy: {score[1]}')","metadata":{"execution":{"iopub.status.busy":"2021-12-26T10:32:52.441291Z","iopub.execute_input":"2021-12-26T10:32:52.442070Z","iopub.status.idle":"2021-12-26T10:32:57.702307Z","shell.execute_reply.started":"2021-12-26T10:32:52.442022Z","shell.execute_reply":"2021-12-26T10:32:57.701516Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"## Limitation des ressources (simple CNN)","metadata":{}},{"cell_type":"code","source":"def build_cnn():\n    model = keras.Sequential([\n        keras.Input(shape=(SIZE,SIZE,4), name='Original_Images'),\n        keras.layers.Conv2D(input_shape=(140,140,1), filters=32, kernel_size=11, \n                            strides=1, activation='relu', name='Conv1'),\n        keras.layers.Conv2D(input_shape=(130,130,32), filters=32, kernel_size=11, \n                            strides=1, activation='relu', name='Conv2'),\n        keras.layers.MaxPool2D(pool_size=(5, 5), strides=2,padding='same'),\n        keras.layers.Conv2D(input_shape=(58,58,32), filters=64, kernel_size=9, \n                            strides=1, activation='relu', name='Conv3'),\n        keras.layers.MaxPool2D(pool_size=(5, 5), strides=2,padding='same'),\n        keras.layers.Conv2D(input_shape=(23,23,64), filters=128, kernel_size=8, \n                            strides=1, activation='relu', name='Conv4'),\n        keras.layers.Conv2D(input_shape=(16,16,128), filters=256, kernel_size=9, \n                            strides=1, activation='relu', name='Conv5'),\n        keras.layers.Conv2D(input_shape=(8,8,256), filters=256, kernel_size=8, \n                            strides=1, activation='relu', name='Conv6'),    \n\n        keras.layers.Flatten(),\n        keras.layers.Dense(8, activation=tf.keras.activations.relu, name='Dense')\n    ])\n    print(model.summary())\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-26T10:33:03.479234Z","iopub.execute_input":"2021-12-26T10:33:03.479504Z","iopub.status.idle":"2021-12-26T10:33:03.489721Z","shell.execute_reply.started":"2021-12-26T10:33:03.479474Z","shell.execute_reply":"2021-12-26T10:33:03.488769Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"def build_mlp():\n    model = keras.Sequential([\n        keras.Input(shape=24, name='Extracted_Traditional_Features'),\n        keras.layers.Dense(8, activation=tf.keras.activations.relu, name='Dense1'),\n        keras.layers.Dense(4, activation=tf.keras.activations.relu, name='Dense2')\n    ])\n    print(model.summary())\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-26T10:33:06.947294Z","iopub.execute_input":"2021-12-26T10:33:06.947665Z","iopub.status.idle":"2021-12-26T10:33:06.957229Z","shell.execute_reply.started":"2021-12-26T10:33:06.947620Z","shell.execute_reply":"2021-12-26T10:33:06.955385Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"mlp = build_mlp()\ncnn = build_cnn()\n\ncombinedInput = concatenate([mlp.output, cnn.output])\n\nx = Dense(8, activation=\"relu\")(combinedInput)\nx = Dense(3, activation=\"softmax\")(x)\n\nmodel = Model(inputs=[mlp.input, cnn.input], outputs=x)","metadata":{"execution":{"iopub.status.busy":"2021-12-26T10:33:09.291225Z","iopub.execute_input":"2021-12-26T10:33:09.291495Z","iopub.status.idle":"2021-12-26T10:33:09.401549Z","shell.execute_reply.started":"2021-12-26T10:33:09.291462Z","shell.execute_reply":"2021-12-26T10:33:09.400819Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=opt, loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n              metrics=[keras.metrics.CategoricalAccuracy()])\n\nplot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-26T10:33:13.728521Z","iopub.execute_input":"2021-12-26T10:33:13.729063Z","iopub.status.idle":"2021-12-26T10:33:14.101989Z","shell.execute_reply.started":"2021-12-26T10:33:13.729025Z","shell.execute_reply":"2021-12-26T10:33:14.101201Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"dataset_inputs = tf.data.Dataset.from_tensor_slices((train_df, tf.expand_dims(train_images_norm, axis=-1)))\ndataset_label = tf.data.Dataset.from_tensor_slices(train_labels)\n\ndataset = tf.data.Dataset.zip((dataset_inputs, dataset_label)).batch(BATCH_SIZE).repeat()\nSTEP_SIZE_TRAIN= train_images_norm.shape[0]//BATCH_SIZE\n# fit model\nwith tf.device('/gpu:0'):\n    print('runnning from gpu')\n    history = model.fit(dataset, \n                    validation_data=([val_df, tf.expand_dims(val_images_norm, axis=-1)], val_labels),\n                    epochs = EPOCH_NUM, steps_per_epoch=STEP_SIZE_TRAIN, callbacks=cb)","metadata":{"execution":{"iopub.status.busy":"2021-12-26T10:34:24.788192Z","iopub.execute_input":"2021-12-26T10:34:24.789009Z","iopub.status.idle":"2021-12-26T10:43:52.265205Z","shell.execute_reply.started":"2021-12-26T10:34:24.788971Z","shell.execute_reply":"2021-12-26T10:43:52.264483Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"model.save(\"mlp_cnn_200itrs_new.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-12-26T10:49:18.796864Z","iopub.execute_input":"2021-12-26T10:49:18.797130Z","iopub.status.idle":"2021-12-26T10:49:19.721204Z","shell.execute_reply.started":"2021-12-26T10:49:18.797100Z","shell.execute_reply":"2021-12-26T10:49:19.720284Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"./mlp_cnn_200itrs_new.h5\"> Download File </a>","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing","metadata":{}},{"cell_type":"code","source":"test_inputs = tf.data.Dataset.from_tensor_slices((test_df, tf.expand_dims(test_images_norm, axis=-1)))\n# test_labels = tf.data.Dataset.from_tensor_slices(test_labels)\n\ntest_dataset = tf.data.Dataset.zip((test_inputs, test_labels)).batch(BATCH_SIZE).repeat()\nSTEP_SIZE_TEST= test_images_norm.shape[0]//BATCH_SIZE\n\nscore = model.evaluate(test_dataset, batch_size=BATCH_SIZE, steps=STEP_SIZE_TEST )\nprint(f'Test loss: {score[0]} / Test accuracy: {score[1]}')","metadata":{"execution":{"iopub.status.busy":"2021-12-26T10:55:55.488751Z","iopub.execute_input":"2021-12-26T10:55:55.489288Z","iopub.status.idle":"2021-12-26T10:55:56.773828Z","shell.execute_reply.started":"2021-12-26T10:55:55.489252Z","shell.execute_reply":"2021-12-26T10:55:56.773112Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nhistory.history.keys()","metadata":{"execution":{"iopub.status.busy":"2021-12-26T10:55:58.892867Z","iopub.execute_input":"2021-12-26T10:55:58.893585Z","iopub.status.idle":"2021-12-26T10:55:58.900157Z","shell.execute_reply.started":"2021-12-26T10:55:58.893545Z","shell.execute_reply":"2021-12-26T10:55:58.899238Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['categorical_accuracy'])\nplt.plot(history.history['val_categorical_accuracy'])\nplt.title('Accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-26T10:56:00.353419Z","iopub.execute_input":"2021-12-26T10:56:00.353975Z","iopub.status.idle":"2021-12-26T10:56:00.587226Z","shell.execute_reply.started":"2021-12-26T10:56:00.353938Z","shell.execute_reply":"2021-12-26T10:56:00.586456Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Loss curve')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-26T10:56:01.872885Z","iopub.execute_input":"2021-12-26T10:56:01.873458Z","iopub.status.idle":"2021-12-26T10:56:02.166491Z","shell.execute_reply.started":"2021-12-26T10:56:01.873390Z","shell.execute_reply":"2021-12-26T10:56:02.165656Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}