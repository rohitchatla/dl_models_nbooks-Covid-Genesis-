{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install imutils","metadata":{"execution":{"iopub.status.busy":"2021-12-23T11:12:41.31575Z","iopub.execute_input":"2021-12-23T11:12:41.316079Z","iopub.status.idle":"2021-12-23T11:12:52.06458Z","shell.execute_reply.started":"2021-12-23T11:12:41.316009Z","shell.execute_reply":"2021-12-23T11:12:52.063697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.xception import Xception\nfrom keras.layers import AveragePooling2D\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras.layers import Input\nfrom keras.models import Model\nfrom tensorflow.keras.optimizers import Adam,Adamax\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom imutils import paths\nimport shutil\nimport random\nimport cv2\nimport argparse\nimport os\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2021-12-23T11:12:52.066613Z","iopub.execute_input":"2021-12-23T11:12:52.066869Z","iopub.status.idle":"2021-12-23T11:12:57.721913Z","shell.execute_reply.started":"2021-12-23T11:12:52.066833Z","shell.execute_reply":"2021-12-23T11:12:57.720858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!gdown --id 1bFrktIYGOp9cU7o6QBL8cv2QGToONh-W\n!gdown --id 1uCB5XydEqICQnGCWRWc2xXCg0exLhjc_","metadata":{"execution":{"iopub.status.busy":"2021-12-23T11:12:57.72745Z","iopub.execute_input":"2021-12-23T11:12:57.727771Z","iopub.status.idle":"2021-12-23T11:12:59.587889Z","shell.execute_reply.started":"2021-12-23T11:12:57.727734Z","shell.execute_reply":"2021-12-23T11:12:59.587083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np \nimport os \nimport shutil\nimport glob\nimport matplotlib.pyplot as plt\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2021-12-23T11:12:59.591151Z","iopub.execute_input":"2021-12-23T11:12:59.59138Z","iopub.status.idle":"2021-12-23T11:12:59.595796Z","shell.execute_reply.started":"2021-12-23T11:12:59.591351Z","shell.execute_reply":"2021-12-23T11:12:59.594857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! conda install openpyxl -y","metadata":{"execution":{"iopub.status.busy":"2021-12-23T11:12:59.597175Z","iopub.execute_input":"2021-12-23T11:12:59.597629Z","iopub.status.idle":"2021-12-23T11:13:59.068359Z","shell.execute_reply.started":"2021-12-23T11:12:59.597587Z","shell.execute_reply":"2021-12-23T11:13:59.067364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device_name = tf.test.gpu_device_name()\nif \"GPU\" not in device_name:\n    print(\"GPU device not found\")\nprint('Found GPU at: {}'.format(device_name))\n\nplt.rcParams['figure.figsize'] = [8.0, 8.0]\nplt.rcParams['figure.dpi'] = 100","metadata":{"execution":{"iopub.status.busy":"2021-12-23T11:13:59.070194Z","iopub.execute_input":"2021-12-23T11:13:59.07047Z","iopub.status.idle":"2021-12-23T11:14:01.06919Z","shell.execute_reply.started":"2021-12-23T11:13:59.070432Z","shell.execute_reply":"2021-12-23T11:14:01.066198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datanom = pd.read_excel('../input/normal/Normal.metadata.xlsx')\ndatanom['FILE NAME'][0]\ndatacov = pd.read_excel('../input/covid19-radiography-database/COVID-19_Radiography_Dataset/COVID.metadata.xlsx')\ndatacov['FILE NAME'][0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\noutput = '/kaggle/working/data/'\ntry:\n    os.mkdir(output)\n    os.mkdir(output+'/Normal')\n    os.mkdir(output+'/COVID')\n\nexcept Exception as e :\n    print(e)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(1500): #1500\n    dest = './data/Normal/'+datanom['FILE NAME'][i]+'.png'\n    src = '../input/covid19-radiography-database/COVID-19_Radiography_Dataset/Normal/'+datanom['FILE NAME'][i]+'.png' #//content/gdrive/My Drive/data_set/all/\n    shutil.copyfile(src, dest)\n    dest = './data/COVID/'+datacov['FILE NAME'][i]+'.png'\n    src = '../input/covid19-radiography-database/COVID-19_Radiography_Dataset/COVID/'+datacov['FILE NAME'][i]+'.png' #//content/gdrive/My Drive/data_set/all/\n    shutil.copyfile(src, dest)\nprint('ok')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_path='./data'\nprint(\"[INFO] loading images...\")\nimagePaths = list(paths.list_images(dataset_path))\ndata = []\nlabels = []\n# loop over the image paths\nfor imagePath in imagePaths:\n    # extract the class label from the filename\n    label = imagePath.split(os.path.sep)[-2]\n    # load the image, swap color channels, and resize it to be a fixed\n    # 224x224 pixels while ignoring aspect ratio\n    image = cv2.imread(imagePath)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = cv2.resize(image, (224, 224))\n    # update the data and labels lists, respectively\n    data.append(image)\n    labels.append(label)\n# convert the data and labels to NumPy arrays while scaling the pixel\n# intensities to the range [0, 1]\ndata = np.array(data) / 255.0\nlabels = np.array(labels)\nprint(\"[INFO] Images successfully loaded\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"covid_imgs = pd.read_excel(\"../input/covid19-radiography-database/COVID-19_Radiography_Dataset/COVID.metadata.xlsx\", engine='openpyxl')\ncovid_imgs.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T11:14:01.07045Z","iopub.execute_input":"2021-12-23T11:14:01.070795Z","iopub.status.idle":"2021-12-23T11:14:01.608465Z","shell.execute_reply.started":"2021-12-23T11:14:01.070755Z","shell.execute_reply":"2021-12-23T11:14:01.60771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opacity_imgs = pd.read_excel(\"../input/covid19-radiography-database/COVID-19_Radiography_Dataset/Lung_Opacity.metadata.xlsx\", engine='openpyxl')\nopacity_imgs.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T11:14:01.609974Z","iopub.execute_input":"2021-12-23T11:14:01.610434Z","iopub.status.idle":"2021-12-23T11:14:02.178572Z","shell.execute_reply.started":"2021-12-23T11:14:01.610397Z","shell.execute_reply":"2021-12-23T11:14:02.177735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"normal_imgs = pd.read_excel(\"../input/covid19-radiography-database/COVID-19_Radiography_Dataset/Normal.metadata.xlsx\", engine='openpyxl')\nnormal_imgs.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T11:14:02.179934Z","iopub.execute_input":"2021-12-23T11:14:02.181081Z","iopub.status.idle":"2021-12-23T11:14:03.121566Z","shell.execute_reply.started":"2021-12-23T11:14:02.181039Z","shell.execute_reply":"2021-12-23T11:14:03.120789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pneumonia_imgs = pd.read_excel(\"../input/covid19-radiography-database/COVID-19_Radiography_Dataset/Viral Pneumonia.metadata.xlsx\", engine='openpyxl')\npneumonia_imgs.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T11:14:03.124692Z","iopub.execute_input":"2021-12-23T11:14:03.124889Z","iopub.status.idle":"2021-12-23T11:14:03.273244Z","shell.execute_reply.started":"2021-12-23T11:14:03.124865Z","shell.execute_reply":"2021-12-23T11:14:03.272436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ROOT_DIR = \"../input/covid19-radiography-database/COVID-19_Radiography_Dataset/\"\nimgs = ['COVID','Lung_Opacity','Normal','Viral Pneumonia']\n\nNEW_DIR = \"./all_images/\"","metadata":{"execution":{"iopub.status.busy":"2021-12-23T11:14:03.274605Z","iopub.execute_input":"2021-12-23T11:14:03.274869Z","iopub.status.idle":"2021-12-23T11:14:03.279366Z","shell.execute_reply.started":"2021-12-23T11:14:03.274833Z","shell.execute_reply":"2021-12-23T11:14:03.2783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(imgs[0])\nprint(imgs[1])\nprint(imgs[2])\nprint(imgs[3])","metadata":{"execution":{"iopub.status.busy":"2021-12-23T11:14:03.280865Z","iopub.execute_input":"2021-12-23T11:14:03.28117Z","iopub.status.idle":"2021-12-23T11:14:03.289775Z","shell.execute_reply.started":"2021-12-23T11:14:03.281135Z","shell.execute_reply":"2021-12-23T11:14:03.288949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not os.path.exists(NEW_DIR):\n    os.mkdir(NEW_DIR)\n    \n    for i in imgs:\n        org_dir = os.path.join(ROOT_DIR,i+\"/\")\n        \n        for imgfile in glob.iglob(os.path.join(org_dir,\"*.png\")):\n            shutil.copy(imgfile,NEW_DIR)\nelse:\n    print(\"Already Exist\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"counter = {\"COVID\":0,\"Lung_Opacity\":0,\"Normal\":0,\"Viral Pneumonia\":0}\n\nfor image in imgs:\n    for count in glob.iglob(NEW_DIR+image+\"*\"):\n        counter[image] += 1\n\nprint(counter)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams['figure.figsize'] = [15,7]\nplt.bar(x=counter.keys(),height=counter.values())\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not os.path.exists(NEW_DIR+\"train_test_split/\"):\n    \n    os.makedirs(NEW_DIR+\"train_test_split/\")\n    \n    os.makedirs(NEW_DIR+\"train_test_split/train/COVID\")\n    os.makedirs(NEW_DIR+\"train_test_split/test/COVID\")\n    os.makedirs(NEW_DIR+\"train_test_split/validation/COVID\")\n    \n    os.makedirs(NEW_DIR+\"train_test_split/train/Normal\")\n    os.makedirs(NEW_DIR+\"train_test_split/test/Normal\")\n    os.makedirs(NEW_DIR+\"train_test_split/validation/Normal\")\n    \n    os.makedirs(NEW_DIR+\"train_test_split/train/Lung Opacity\")\n    os.makedirs(NEW_DIR+\"train_test_split/test/Lung Opacity\")\n    os.makedirs(NEW_DIR+\"train_test_split/validation/Lung Opacity\")\n    \n    os.makedirs(NEW_DIR+\"train_test_split/train/Viral Pneumonia\")\n    os.makedirs(NEW_DIR+\"train_test_split/test/Viral Pneumonia\")\n    os.makedirs(NEW_DIR+\"train_test_split/validation/Viral Pneumonia\")\n    \n    for i in np.random.choice(replace= False , size= 2531 , a = glob.glob(NEW_DIR+imgs[0]+\"*\") ):\n        shutil.copy(i , NEW_DIR+\"train_test_split/train/Covid\" )\n        os.remove(i)\n\n    for i in np.random.choice(replace= False , size= 7134 , a = glob.glob(NEW_DIR+imgs[2]+\"*\") ):\n        shutil.copy(i , NEW_DIR+\"train_test_split/train/Normal\" )\n        os.remove(i)\n        \n    for i in np.random.choice(replace= False , size= 4208 , a = glob.glob(NEW_DIR+imgs[1]+\"*\") ):\n        shutil.copy(i , NEW_DIR+\"train_test_split/train/Lung Opacity\" )\n        os.remove(i)\n\n    for i in np.random.choice(replace= False , size= 941 , a = glob.glob(NEW_DIR+imgs[3]+\"*\") ):\n        shutil.copy(i , NEW_DIR+\"train_test_split/train/Viral Pneumonia\" )\n        os.remove(i)\n\n    # Validation Data\n    for i in np.random.choice(replace= False , size= 723 , a = glob.glob(NEW_DIR+imgs[0]+\"*\") ):\n        shutil.copy(i , NEW_DIR+\"train_test_split/validation/Covid\" )\n        os.remove(i)\n\n    for i in np.random.choice(replace= False , size= 2038 , a = glob.glob(NEW_DIR+imgs[2]+\"*\") ):\n        shutil.copy(i , NEW_DIR+\"train_test_split/validation/Normal\" )\n        os.remove(i)\n        \n    for i in np.random.choice(replace= False , size= 1202 , a = glob.glob(NEW_DIR+imgs[1]+\"*\") ):\n        shutil.copy(i , NEW_DIR+\"train_test_split/validation/Lung Opacity\" )\n        os.remove(i)\n\n    for i in np.random.choice(replace= False , size= 269 , a = glob.glob(NEW_DIR+imgs[3]+\"*\") ):\n        shutil.copy(i , NEW_DIR+\"train_test_split/validation/Viral Pneumonia\" )\n        os.remove(i)\n\n\n    # Test Data\n    for i in np.random.choice(replace= False , size= 362 , a = glob.glob(NEW_DIR+imgs[0]+\"*\") ):\n        shutil.copy(i , NEW_DIR+\"train_test_split/test/Covid\" )\n        os.remove(i)\n\n    for i in np.random.choice(replace= False , size= 1020 , a = glob.glob(NEW_DIR+imgs[2]+\"*\") ):\n        shutil.copy(i , NEW_DIR+\"train_test_split/test/Normal\" )\n        os.remove(i)\n        \n    for i in np.random.choice(replace= False , size= 602 , a = glob.glob(NEW_DIR+imgs[1]+\"*\") ):\n        shutil.copy(i , NEW_DIR+\"train_test_split/test/Lung Opacity\" )\n        os.remove(i)\n\n    for i in np.random.choice(replace= False , size= 135 , a = glob.glob(NEW_DIR+imgs[3]+\"*\") ):\n        shutil.copy(i , NEW_DIR+\"train_test_split/test/Viral Pneumonia\" )\n        os.remove(i)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_path  = \"./all_images/train_test_split/train\"\nvalid_path  = \"./all_images/train_test_split/validation\"\ntest_path   = \"./all_images/train_test_split/test\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications import vgg16\nfrom keras.models import Model\nfrom keras.layers import Dense, MaxPool2D, Conv2D\nimport keras","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_gen = ImageDataGenerator(preprocessing_function= vgg16.preprocess_input , zoom_range= 0.2, horizontal_flip= True, shear_range= 0.2 , rescale= 1./255)\ntrain = train_data_gen.flow_from_directory(directory= train_path , target_size=(224,224))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_data_gen = ImageDataGenerator(preprocessing_function= vgg16.preprocess_input , rescale= 1./255 )\nvalid = validation_data_gen.flow_from_directory(directory= valid_path , target_size=(224,224))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data_gen = ImageDataGenerator(preprocessing_function= vgg16.preprocess_input, rescale= 1./255 )\ntest = train_data_gen.flow_from_directory(directory= test_path , target_size=(224,224), shuffle= False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.class_indices","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_type = {0:'COVID', 1:'Lung Opacity', 2:'Normal', 3:'Viral Pneumonia'}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t_img , label = train.next()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(t_img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plotImages(img_arr, label):\n    \n  for im, l in zip(img_arr,label) :\n    plt.figure(figsize= (5,5))\n    plt.imshow(im, cmap = 'gray')\n    plt.title(im.shape)\n    plt.axis = False\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plotImages(t_img, label)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Model, Sequential\nimport numpy as np\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D,AveragePooling2D\nfrom tensorflow.keras.optimizers import Adam,Adamax\nfrom tensorflow.keras.layers import Dense, Flatten,Dropout\nfrom tensorflow.keras.models import Model\nfrom keras.models import Model\nfrom keras.layers import Flatten, Dense\nfrom keras.applications.xception import Xception\nfrom tensorflow import keras\nimport matplotlib.cm as cm\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.layers.experimental.preprocessing import Resizing, Rescaling\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport time\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now we will create a One-Hot encoding to the list of labels to make the classfication\n# integer encode\nlb_encoder = LabelEncoder()\nlabels = lb_encoder.fit_transform(labels)\nlabels = to_categorical(labels)\n\n\n# Split the data into training and testing using the 80% of training and 20% to testing\nX_train, X_test, y_train, y_test = train_test_split(data, labels, test_size = 0.2, stratify = labels,random_state = 42)\n\n\n# Set the image augmentation of the training data\ntrainAug = ImageDataGenerator(rotation_range= 15, fill_mode='nearest')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"INIT_LR = 1e-3\nEPOCHS = 100\nBS = 8\nbase_model = Xception(weights = 'imagenet', include_top=False, input_tensor=Input(shape=(224,224,3)))\nheadmodel = base_model.output\nheadmodel = AveragePooling2D(pool_size =(4, 4))(headmodel)\nheadmodel = Flatten(name ='Flatten')(headmodel)\nheadmodel = Dense(64, activation = 'relu')(headmodel)\nheadmodel = Dropout(0.5)(headmodel)\nheadmodel = Dense(4, activation = 'softmax')(headmodel)#2>Dense(2, activation = 'softmax')(headmodel)\n\nmodel = Model(inputs = base_model.input, outputs = headmodel)\n\nfor layers in base_model.layers:\n    layers.trainable = False\n\n\nopt = Adam(lr = INIT_LR, decay = INIT_LR/EPOCHS)\nmodel.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with tf.device('/gpu:0'):\n    print(\"Training the model with gpu . . .\")\n#     hist = model.fit_generator(trainAug.flow(X_train, y_train, batch_size = BS),steps_per_epoch=len(X_train) // BS, validation_data=(X_test, y_test), validation_steps=len(X_test) // BS, epochs=100)\n    hist = model.fit_generator(train, steps_per_epoch= len(train) // BS, epochs= 100, validation_data= valid , validation_steps= len(test) // BS)#, callbacks=[es,mc])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"xception.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplot(211)\nplt.title('Categorical Crossentropy Loss')\nplt.plot(hist.history['loss'], color ='red', label='train')\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.plot(hist.history['val_loss'], color ='green', label='val')\n\nplt.show()\n\nplt.subplot(212)\nplt.title('Classification Accuracy')\nplt.plot(hist.history['accuracy'], color='red', label='train')\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.plot(hist.history['val_accuracy'], color='green', label='test')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# make predictions on the testing set\nprint(\"[INFO] evaluating network...\")\npredIdxs = model.predict(X_test, batch_size=BS)\n# for each image in the testing set we need to find the index of the\n# label with corresponding largest predicted probability\npredIdxs = np.argmax(predIdxs, axis=1)\n# show a nicely formatted classification report\nprint(classification_report(y_test.argmax(axis=1), predIdxs, target_names=lb_encoder.classes_))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compute the confusion matrix and and use it to derive the raw\n# accuracy, sensitivity, and specificity\ncm = confusion_matrix(y_test.argmax(axis=1), predIdxs)\ntotal = sum(sum(cm))\nacc = (cm[0, 0] + cm[1, 1]) / total\nsensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\nspecificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n# show the accuracy, sensitivity, and specificity of the test\nprint(\"accuracy: {:.4f}\".format(acc))\nprint(\"sensitivity: {:.4f}\".format(sensitivity))\nprint(\"specificity: {:.4f}\".format(specificity))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('./vgg19.h5')\nimport pandas as pd\nhist_df = pd.DataFrame(hist.history) \nhist_csv_file = 'history.csv'\nwith open(hist_csv_file, mode='w') as f:\n    hist_df.to_csv(f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import itertools\n\ndef plot_confusion_matrix(cm, classes,\n                           normalize=False,\n                           title='Confusion matrix',\n                           cmap=plt.cm.Blues):\n     \"\"\"\n     This function prints and plots the confusion matrix.\n     Normalization can be applied by setting `normalize=True`.\n     \"\"\"\n     \n     plt.imshow(cm, interpolation='nearest', cmap=cmap)\n     plt.title(title)\n     plt.colorbar()\n     tick_marks = np.arange(len(classes))\n     plt.xticks(tick_marks, classes, rotation=45)\n     plt.yticks(tick_marks, classes)\n\n     if normalize:\n         cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n         print(\"Normalized confusion matrix\")\n     else:\n         print('Confusion matrix, without normalization')\n\n     print(cm)\n\n     thresh = cm.max() / 2.\n     for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n         plt.text(j, i, cm[i, j],\n             horizontalalignment=\"center\",\n             color=\"white\" if cm[i, j] > thresh else \"black\")\n\n     plt.tight_layout()\n     plt.ylabel('True label')\n     plt.xlabel('Predicted label')\n     plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def score(model,shape):\n  predict = model.predict(X_test, batch_size=BS)\n  predict = np.argmax(predict, axis=1)\n  cm = confusion_matrix(y_test.argmax(axis=1), predict)\n  cm_plot_labels = ['COVID-19','Normal']\n  plot_confusion_matrix(cm, classes=cm_plot_labels, title='Confusion Matrix') \n  accuracy = (cm[0][0]+cm[1][1])/(cm[0][0]+cm[0][1]+cm[1][0]+cm[1][1])\n  recall = (cm[0][0])/(cm[0][0]+cm[1][0])\n  presition = (cm[0][0])/(cm[0][0]+cm[0][1])\n  specificity = (cm[1][1])/(cm[1][1]+cm[0][1])\n  f1 = 2*presition*recall/(presition+recall)\n  print(f'accuracy = {accuracy}\\nrecall = {recall}\\npresition = {presition}\\nspecificity = {specificity}\\nf1 = {f1}')\n  fpr, tpr, threshold = metrics.roc_curve(y_test.argmax(axis=1), predict)\n  roc_auc = metrics.auc(fpr, tpr)\n  plt.title('Receiver Operating Characteristic')\n  plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n  plt.legend(loc = 'lower right')\n  plt.plot([0, 1], [0, 1],'r--')\n  plt.xlim([0, 1])\n  plt.ylim([0, 1])\n  plt.ylabel('True Positive Rate')\n  plt.xlabel('False Positive Rate')\n  plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn.metrics as metrics\n\nscore(model,224)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_img_array(img_path, size):\n    img = tf.keras.preprocessing.image.load_img(img_path, target_size=size)\n    array = tf.keras.preprocessing.image.img_to_array(img)\n    # We add a dimension to transform our array into a \"batch\"\n    # of size \"size\"\n    array = np.expand_dims(array, axis=0)\n    return array\n\ndef make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n    # First, we create a model that maps the input image to the activations\n    # of the last conv layer as well as the output predictions\n    grad_model = tf.keras.models.Model(\n        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n    )\n\n    # Then, we compute the gradient of the top predicted class for our input image\n    # with respect to the activations of the last conv layer\n    with tf.GradientTape() as tape:\n        last_conv_layer_output, preds = grad_model(img_array)\n        if pred_index is None:\n            pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n\n    # This is the gradient of the output neuron (top predicted or chosen)\n    # with regard to the output feature map of the last conv layer\n    grads = tape.gradient(class_channel, last_conv_layer_output)\n\n    # This is a vector where each entry is the mean intensity of the gradient\n    # over a specific feature map channel\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    # We multiply each channel in the feature map array\n    # by \"how important this channel is\" with regard to the top predicted class\n    # then sum all the channels to obtain the heatmap class activation\n    last_conv_layer_output = last_conv_layer_output[0]\n    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n\n    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    return heatmap.numpy()\n\ndef save_and_display_gradcam(img, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n    # Rescale heatmap to a range 0-255\n    img = img*255\n    heatmap = np.uint8(255 * heatmap)\n\n    # Use jet colormap to colorize heatmap\n    jet = cm.get_cmap(\"jet\")\n\n    # Use RGB values of the colormap\n    jet_colors = jet(np.arange(256))[:, :3]\n    jet_heatmap = jet_colors[heatmap]\n\n    # Create an image with RGB colorized heatmap\n    jet_heatmap = tf.keras.preprocessing.image.array_to_img(jet_heatmap)\n    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n    jet_heatmap = tf.keras.preprocessing.image.img_to_array(jet_heatmap)\n\n    # Superimpose the heatmap on original image\n    superimposed_img = jet_heatmap*0.4+img\n    superimposed_img = tf.keras.preprocessing.image.array_to_img(superimposed_img)\n\n    # Save the superimposed image\n    superimposed_img.save(cam_path)\n\n    # Display Grad CAM\n#     display(Image(cam_path))\n    \n    return superimposed_img\n    \npreprocess_input = tf.keras.applications.vgg19.preprocess_input\ndecode_predictions = tf.keras.applications.vgg19.decode_predictions\n\nlast_conv_layer_name = \"block5_conv3\"\nimg_size = (224,224)\n\n# Remove last layer's softmax\nmodel.layers[-1].activation = None","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_path = '/content/gdrive/MyDrive/data_set/test/COVID/COVID-58.png'\nBS=8\nfrom matplotlib import cm\nplt.figure(figsize=(12, 5))\nfor i in range(10):\n    plt.subplot(2, 5, i+1)\n    i=i+100\n    array = np.expand_dims(X_test[i], axis=0)\n    heatmap = make_gradcam_heatmap(array, model, last_conv_layer_name)\n    cam_path = save_and_display_gradcam(X_test[i], heatmap)\n    plt.imshow(cam_path)\n    predict = model.predict(X_test, batch_size=BS)\n    predict = np.argmax(predict, axis=1)\n    plt.title(f'{lb_encoder.inverse_transform(y_test.argmax(axis=1))[i]}==>{lb_encoder.inverse_transform(predict)[i]} ')\nplt.tight_layout()\nplt.show()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('./vgg19.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}